import pandas as pd
import numpy as np
from scipy.optimize import minimize
from scipy.stats import norm
import matplotlib.pyplot as plt

# Set display options to avoid truncation
pd.set_option('display.max_columns', None)  # Show all columns
pd.set_option('display.width', 0)          # Disable line wrapping

# Simulation Function
def run_simulation(num_subjects, num_trials):
    results = []
    true_params = []  # To store true parameters for each subject
    fixed_boundary = 0.2  # Fixed decision boundary at 0.2
    for subject in range(num_subjects):
        sigma = np.random.uniform(0.1, 1.0)  # Only sigma varies
        true_params.append({'subject': subject, 'boundary': fixed_boundary, 'sigma': sigma})  # Save true parameters
        for trial in range(num_trials):
            mu = np.random.uniform(-2, 2)  # Generate a new stimulus (given evidence) mu for each trial
            percept = np.random.normal(mu, sigma)  # Generate percept based on Gaussian(mu, sigma)
            decision = 'right' if percept > fixed_boundary else 'left'  # Use the fixed boundary
            results.append({
                'subject': subject,
                'trial': trial,
                'mu': mu,
                'percept': percept,
                'boundary': fixed_boundary,  # Fixed boundary
                'sigma': sigma,
                'decision': decision
            })
    results_df = pd.DataFrame(results)
    true_params_df = pd.DataFrame(true_params)  # Create a DataFrame for true parameters
    return results_df, true_params_df

# Log-Likelihood Function
def log_likelihood(params, data):
    boundary, sigma = params
    epsilon = 1e-10  # Small value to avoid log(0)
    ll = 0
    for _, row in data.iterrows():
        mu = row['mu']
        decision = row['decision']
        cdf_val = norm.cdf(boundary, loc=mu, scale=sigma)
        if decision == 'right':
            prob = max(1 - cdf_val, epsilon)  # Avoid values too close to 0
        else:
            prob = max(cdf_val, epsilon)  # Avoid values too close to 0
        ll += np.log(prob)
    return -ll

# Parameter Inference Function
def infer_parameters(results_df):
    inferred_params = []
    for subject in results_df['subject'].unique():
        subject_data = results_df[results_df['subject'] == subject]
        initial_guess = [0.5, 0.5]  # boundary, sigma
        bounds = [(0, 1), (0.1, 2)]
        result = minimize(log_likelihood, initial_guess, args=(subject_data,), bounds=bounds)
        inferred_params.append({
            'subject': subject,
            'boundary': result.x[0],
            'sigma': result.x[1]
        })
    return pd.DataFrame(inferred_params)

# Run the simulation
num_subjects = 10
num_trials = 100
results_df, true_params_df = run_simulation(num_subjects, num_trials)

# Infer parameters
inferred_params_df = infer_parameters(results_df)

# Merge inferred and true parameters for comparison
comparison_df = pd.merge(inferred_params_df, true_params_df, on='subject', suffixes=('_inferred', '_true'))

# Calculate differences
comparison_df['boundary_error'] = comparison_df['boundary_inferred'] - comparison_df['boundary_true']
comparison_df['sigma_error'] = comparison_df['sigma_inferred'] - comparison_df['sigma_true']

# Print comparison DataFrame
#print(comparison_df)

# Visualization: Boundary
plt.scatter(comparison_df['boundary_true'], comparison_df['boundary_inferred'], label='Boundary')
plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Perfect Recovery')
plt.xlabel('True Boundary')
plt.ylabel('Inferred Boundary')
plt.legend()
plt.title('Boundary Recovery')
#plt.show()

# Visualization: Sigma
plt.scatter(comparison_df['sigma_true'], comparison_df['sigma_inferred'], label='Sigma')
plt.plot([0.1, 1], [0.1, 1], color='red', linestyle='--', label='Perfect Recovery')
plt.xlabel('True Sigma')
plt.ylabel('Inferred Sigma')
plt.legend()
plt.title('Sigma Recovery')
#plt.show()

# Visualization: Correlation between inferred sigma and inferred boundary
def compute_and_plot_correlation(df):
    correlation = df['boundary_inferred'].corr(df['sigma_inferred'])

    # Scatter plot
    plt.scatter(df['sigma_inferred'], df['boundary_inferred'], label='Inferred')
    plt.plot([0.1, 1], [0.1, 1], color='red', linestyle='--', label='Correlation')
    plt.xlabel('Inferred Sigma')
    plt.ylabel('Inferred Boundary')
    plt.legend()
    plt.title(f'Correlation Between Inferred Sigma & Inferred Boundary\n(r = {correlation:.3f})')
    #plt.show()

    #print(f"Correlation between inferred boundary and inferred sigma: {correlation}")
    #return correlation

for i in range(5):  # Runs it 5 times
    results_df, true_params_df = run_simulation(num_subjects, num_trials)
    inferred_params_df = infer_parameters(results_df)
    comparison_df = pd.merge(inferred_params_df, true_params_df, on='subject', suffixes=('_inferred', '_true'))

    correlation = compute_and_plot_correlation(comparison_df)


# Function to compute MSE across trials
def compute_mse_across_trials(results_df, boundary):
    num_trials_list = results_df['trial'].unique()
    mse_values = []

    for num_trials in num_trials_list:
        subset = results_df[results_df['trial'] <= num_trials]  # Consider trials up to current trial
        inferred_params_df = infer_parameters(subset)  # Infer parameters
        mse = np.mean((inferred_params_df['boundary'] - boundary) ** 2)  # Compute MSE
        mse_values.append(mse)

    return num_trials_list, mse_values


# Compute and plot MSE
num_trials_list, mse_values = compute_mse_across_trials(results_df, 0.2)
plt.plot(num_trials_list, mse_values, marker='o', linestyle='-')
plt.xlabel('Number of Trials')
plt.ylabel('MSE of Inferred Boundary')
plt.title('MSE of Inferred Boundary Across Trials')
plt.show()
